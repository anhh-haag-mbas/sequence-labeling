## Parameters
Language
Variance                (Random initializations)
Models                  (LSTM, bi-lstm, + crf)
Hidden layers
Training algorithms     (SGD, etc.)
Embeddings              (Pretrained, glove, polyglot, task sepecific, etc.)
Feature representations (word, character, byte)
Frameworks
Loss function
mini-batches
epochs
learning rates          (number + decreasing or static)
Dimensionality
Lemma vs Form

Remember to lock down the testing environment and document it thorougly
Should we use fixed seeds?

## Testing
Speed 
Accuracy
Training speed
Convergence time (number of training sets before overfitting)
Standard deviation


## What range of tests do we work with? Which parameters do we limit ourselves on
