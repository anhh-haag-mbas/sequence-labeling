Our experiments ran on AWS EC2 machines. This allowed much computing power. One issue of importance here is how one does the task scheduling. We had our code set up in a way that assumed everything was going to run in a single process on a single server. We quickly realized that, that was not feasible, as dynet was not multithreaded. We then switched to a multiprocess model. We did however not run the same amount of processes concurrently for each framework, as some where multithreaded and some weren't. What one should do if they wish to compare the speed of each network is... We ran into computing issues, a single machine of type XX was simply not fast enough, as such we decided to launch several machines, this had a lot of manual work, of copying things from one machine to the next. If we instead had made a "master" server that had all of the configuration to run and stored all of the results, and then made several "slave" servers that queried the master server for configurations and the saved the results on the master server. Adding more computing power would have been trivial.

Furthermore we observed some odditites when running on AWS compared to our own machines.

Pytorch grinded to a halt on a 32 core machine, and as such we switched the machine runnning pytorch with a 72 core machine. This made pytorch even slower. It turns out [ref] that pytorch's multithreading has problems when run on a high number of cores.

Tensorflows multithreading caused no issues but it did not seem to utilize the cores very efficiently, and as such we ran multiple processes at the same time.

Dynet had no multithreading and as such we run many multiple processes at the same time. Dynet did seem to perform significantly slower on some configurations (took days), that were quite fast on our local development machines (took minutes).

This obviously means that the speed results aren't comparable. 
The speed between 2 identical AWS machines might vary a bit [ref].
We have used 2 different AWS machine archetypes [ref1][ref2], where one is faster than the other, or ine pytorch's case slower.
We did not run a single process at a time, but instead ran multiple processes at the same time.
If we wanted reasonably comparable results, but still within the limits of our computing power, we could have turned off multithreading for pytorch and tensorfor and jut ran everything on its own core.

We cannot make any conclusion on speed deviations between the frameworks other than hint at the fact that for some configurations further reasearch might be required across frameworks.
